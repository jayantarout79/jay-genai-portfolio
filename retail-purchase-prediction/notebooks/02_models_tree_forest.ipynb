{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca07d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "927e972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jkr/Desktop/FutureGoal/pythonprojects/jay-genai-portfolio/retail-purchase-prediction/data/raw/online_shoppers_intention.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4243836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Revenue\"]                                  # True = buyers (positive)\n",
    "X = df.drop(columns=[\"Revenue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1090609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split 80/20 (TrainPool / Temp)\n",
    "X_train_pool, X_temp, y_train_pool, y_temp = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# From the 20% Temp, split 50/50 → Val (10%) / Test (10%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "X_train, y_train = X_train_pool, y_train_pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d59b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weekend\"]=df[\"Weekend\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b15942e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"Month\", \"VisitorType\", \"OperatingSystems\", \"Browser\", \"Region\", \"TrafficType\"]\n",
    "num_cols = [\n",
    "    \"Administrative\", \"Administrative_Duration\",\n",
    "    \"Informational\", \"Informational_Duration\",\n",
    "    \"ProductRelated\", \"ProductRelated_Duration\",\n",
    "    \"BounceRates\", \"ExitRates\", \"PageValues\", \"SpecialDay\",\n",
    "    \"Weekend\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cddb1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb39960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", rf)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc22aa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics\n",
      "Precision: 0.776\n",
      "Recall   : 0.5078534031413613\n",
      "F1       : 0.6139240506329114\n",
      "ROC-AUC  : 0.9324371175045975\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.97      0.94      1042\n",
      "        True       0.78      0.51      0.61       191\n",
      "\n",
      "    accuracy                           0.90      1233\n",
      "   macro avg       0.85      0.74      0.78      1233\n",
      "weighted avg       0.89      0.90      0.89      1233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Validation predictions & probabilities\n",
    "val_pred = pipe.predict(X_val)\n",
    "val_proba = pipe.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"Validation metrics\")\n",
    "print(\"Precision:\", precision_score(y_val, val_pred, zero_division=0))\n",
    "print(\"Recall   :\", recall_score(y_val, val_pred, zero_division=0))\n",
    "print(\"F1       :\", f1_score(y_val, val_pred, zero_division=0))\n",
    "print(\"ROC-AUC  :\", roc_auc_score(y_val, val_proba))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, val_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a81506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, precision_score\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"precision\": make_scorer(precision_score, pos_label=True),\n",
    "    \"f1\": \"f1\",\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "    \"avg_prec\": \"average_precision\"  # area under PR curve\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    \"model__class_weight\": [None, \"balanced\"],\n",
    "    \"model__max_depth\": [None, 6, 10, 14],\n",
    "    \"model__min_samples_leaf\": [1, 3, 5, 10],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__max_features\": [\"sqrt\", 0.5, None],\n",
    "    \"model__n_estimators\": [200, 400],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=pipe,                # your preprocessing + model pipeline\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring,               # multiple metrics\n",
    "    refit=\"precision\",             # or \"f1\" depending on your business choice\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "best = grid.best_estimator_\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(\"CV best precision:\", grid.cv_results_[\"mean_test_precision\"][grid.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f4493",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n\u001b[0;32m----> 3\u001b[0m best \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m      6\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m best\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "best = grid.best_estimator_\n",
    "\n",
    "# Validation\n",
    "val_pred = best.predict(X_val)\n",
    "val_proba = best.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"=== Validation Metrics (threshold=0.50) ===\")\n",
    "print(\"Precision:\", precision_score(y_val, val_pred))\n",
    "print(\"Recall   :\", recall_score(y_val, val_pred))\n",
    "print(\"F1       :\", f1_score(y_val, val_pred))\n",
    "print(\"ROC-AUC  :\", roc_auc_score(y_val, val_proba))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "thresholds = np.linspace(0.50, 0.90, 21)  # sweep 0.50 → 0.90\n",
    "records = []\n",
    "for t in thresholds:\n",
    "    preds_t = (val_proba >= t).astype(int)\n",
    "    p = precision_score(y_val, preds_t, zero_division=0)\n",
    "    r = recall_score(y_val, preds_t, zero_division=0)\n",
    "    f = f1_score(y_val, preds_t, zero_division=0)\n",
    "    records.append((t, p, r, f))\n",
    "\n",
    "# Pick threshold that maximizes precision but keeps recall acceptable (e.g., >= 0.45)\n",
    "records_sorted = sorted(records, key=lambda x: (-x[1], -x[2]))  # sort by precision desc, then recall desc\n",
    "best_t, best_p, best_r, best_f = records_sorted[0]\n",
    "print(f\"\\nBest threshold on VAL (by precision): t={best_t:.2f} | precision={best_p:.3f} | recall={best_r:.3f} | f1={best_f:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627269fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit on Train+Val for final model\n",
    "X_train_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "final_model = grid.best_estimator_\n",
    "final_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Test evaluation\n",
    "test_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "# Use chosen threshold; if you skipped tuning, default to 0.50\n",
    "t = best_t  # or 0.50\n",
    "test_pred = (test_proba >= t).astype(int)\n",
    "\n",
    "print(f\"\\n=== TEST Metrics (threshold={t:.2f}) ===\")\n",
    "print(\"Precision:\", precision_score(y_test, test_pred, zero_division=0))\n",
    "print(\"Recall   :\", recall_score(y_test, test_pred, zero_division=0))\n",
    "print(\"F1       :\", f1_score(y_test, test_pred, zero_division=0))\n",
    "print(\"ROC-AUC  :\", roc_auc_score(y_test, test_proba))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, test_pred, zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83076827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names from the ColumnTransformer + OHE\n",
    "ohe = best.named_steps[\"preprocess\"].named_transformers_[\"cat\"]\n",
    "ohe_features = list(ohe.get_feature_names_out(input_features=[\"Month\",\"VisitorType\",\"OperatingSystems\",\"Browser\",\"Region\",\"TrafficType\"]))\n",
    "num_features = [\n",
    "    \"Administrative\", \"Administrative_Duration\",\n",
    "    \"Informational\", \"Informational_Duration\",\n",
    "    \"ProductRelated\", \"ProductRelated_Duration\",\n",
    "    \"BounceRates\", \"ExitRates\", \"PageValues\", \"SpecialDay\", \"Weekend\"\n",
    "]\n",
    "all_features = ohe_features + num_features\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "rf = final_model.named_steps[\"model\"]\n",
    "imp = pd.Series(rf.feature_importances_, index=all_features).sort_values(ascending=False)\n",
    "print(\"\\nTop 15 features driving predictions:\\n\", imp.head(15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
